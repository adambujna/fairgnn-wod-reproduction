{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Manipulation",
   "id": "c98fb56142c4b6a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### This code is used to read the data using `dgl` and save into pytorch, so it's framework-agnostic.\n",
    "\n",
    "This way, the whole code can be converted to use PyTorch only and not have to rely on old PyTorch and CUDA due to `dgl` requirements."
   ],
   "id": "e4e7c86a9e63c48d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T01:07:28.562809Z",
     "start_time": "2026-01-19T01:07:28.559870Z"
    }
   },
   "source": [
    "# # Uncomment to download data\n",
    "# !if [ ! -s \"../data/dblp.bin\" ] && [ -s \"../data/pokec_n.bin\" ] && [ -s \"../data/pokec_z.bin\" ]; then sh ../data/download_datasets.sh && unzip -o ../data/data.zip -d ../data && rm ../data/data.zip && else echo \"Skipping download. Files already exist.\" && fi"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T01:07:30.728286Z",
     "start_time": "2026-01-19T01:07:28.563943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import dgl\n",
    "from src.paths import DATA_DIR"
   ],
   "id": "1919560a59ddca5f",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Read using `dgl` and save using PyTorch.**",
   "id": "d375f75dd840922e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T01:07:31.623089Z",
     "start_time": "2026-01-19T01:07:30.729142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for data_file in ['dblp.bin', 'pokec_n.bin', 'pokec_z.bin']:\n",
    "    path = DATA_DIR + \"/\" + data_file\n",
    "    graph_list, _ = dgl.load_graphs(path)\n",
    "    print(data_file)\n",
    "    print(graph_list)\n",
    "    g = graph_list[0]\n",
    "    \n",
    "    idx_train = torch.where(g.ndata['train_index'])[0]\n",
    "    idx_val   = torch.where(g.ndata['val_index'])[0]\n",
    "    idx_test  = torch.where(g.ndata['test_index'])[0]\n",
    "    \n",
    "    index_split = {\n",
    "        'train_index': idx_train,\n",
    "        'val_index': idx_val,\n",
    "        'test_index': idx_test\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        'num_nodes': g.num_nodes(),\n",
    "        'edge_index': torch.stack(g.edges(), dim=0),\n",
    "        'x': g.ndata['feature'],\n",
    "        'y': g.ndata['label'],\n",
    "        'sensitive': g.ndata['sensitive'],\n",
    "        'split': index_split\n",
    "    }\n",
    "    new_path = DATA_DIR + \"/\" + data_file[:-4] + \".pt\"\n",
    "    torch.save(data, new_path)\n",
    "    print(\"saved\", new_path, \"\\n\")"
   ],
   "id": "ea44bfb3f2c37933",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T01:08:33.556664Z",
     "start_time": "2026-01-19T01:08:33.553547Z"
    }
   },
   "cell_type": "code",
   "source": "# !zip -j ../data/data_pt.zip ../data/dblp.pt ../data/pokec_n.pt ../data/pokec_z.pt -x \"*.DS_Store\" -x \"**/.*\" -x \"__MACOSX\"",
   "id": "9e9ab0e0453ffc8d",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### This code is used to download the credit dataset in `.csv` and `.txt` format and convert it into a matching format to the others.\n",
    "\n",
    "The original datasets are downloaded from the repository and in the format of the PyG-Debias library (https://github.com/yushundong/PyGDebias/)."
   ],
   "id": "d8df398834b9ee8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-26T16:50:49.131537Z",
     "start_time": "2026-01-26T16:50:47.518666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!wget -O ../data/credit.csv https://raw.githubusercontent.com/PyGDebias-Team/data/main/2023-7-26/credit/credit.csv\n",
    "!wget -O ../data/credit_edges.txt https://raw.githubusercontent.com/PyGDebias-Team/data/main/2023-7-26/credit/credit_edges.txt"
   ],
   "id": "d973c46e1267164b",
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T20:08:29.843924Z",
     "start_time": "2026-01-28T20:08:29.540849Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "CSV_PATH = DATA_DIR + \"credit.csv\"\n",
    "EDGE_PATH = DATA_DIR + \"credit_edges.txt\"\n",
    "OUTPUT_NAME = \"credit_no_self_loops.pt\"\n",
    "\n",
    "np.random.seed(0)   # For reproducible train, val, test indexes\n",
    "torch.manual_seed(0)    # For reproducible train, val, test indexes\n",
    "\n",
    "# load \n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# label and sensitive attribute\n",
    "y = torch.tensor(df[\"NoDefaultNextMonth\"].values, dtype=torch.long)\n",
    "sensitive = torch.tensor(df[\"Age\"].values, dtype=torch.long)\n",
    "\n",
    "# node features (drop label & sensitive)\n",
    "feature_cols = df.columns.drop([\"NoDefaultNextMonth\", \"Age\"])\n",
    "x = torch.tensor(df[feature_cols].values, dtype=torch.float32)\n",
    "\n",
    "num_nodes = len(df)\n",
    "\n",
    "# ----------------------------\n",
    "# Load edges\n",
    "# ----------------------------\n",
    "edges = np.loadtxt(EDGE_PATH)\n",
    "\n",
    "# convert scientific notation to int\n",
    "src = torch.tensor(edges[:, 0], dtype=torch.long)\n",
    "dst = torch.tensor(edges[:, 1], dtype=torch.long)\n",
    "\n",
    "edge_index = torch.stack([src, dst], dim=0)\n",
    "\n",
    "\n",
    "# train/val/test split stratified by label\n",
    "label_idx_0 = np.where(y.numpy() == 0)[0]\n",
    "label_idx_1 = np.where(y.numpy() == 1)[0]\n",
    "\n",
    "np.random.shuffle(label_idx_0)\n",
    "np.random.shuffle(label_idx_1)\n",
    "\n",
    "label_number = min(len(label_idx_0), len(label_idx_1)) * 2\n",
    "\n",
    "idx_train = np.append(\n",
    "    label_idx_0[: min(int(0.5 * len(label_idx_0)), label_number // 2)],\n",
    "    label_idx_1[: min(int(0.5 * len(label_idx_1)), label_number // 2)],\n",
    ")\n",
    "\n",
    "idx_val = np.append(\n",
    "    label_idx_0[int(0.5 * len(label_idx_0)) : int(0.75 * len(label_idx_0))],\n",
    "    label_idx_1[int(0.5 * len(label_idx_1)) : int(0.75 * len(label_idx_1))],\n",
    ")\n",
    "\n",
    "idx_test = np.append(\n",
    "    label_idx_0[int(0.75 * len(label_idx_0)) :],\n",
    "    label_idx_1[int(0.75 * len(label_idx_1)) :],\n",
    ")\n",
    "\n",
    "idx_train = torch.tensor(idx_train, dtype=torch.long)\n",
    "idx_val   = torch.tensor(idx_val, dtype=torch.long)\n",
    "idx_test  = torch.tensor(idx_test, dtype=torch.long)\n",
    "\n",
    "index_split = {\n",
    "    \"train_index\": idx_train,\n",
    "    \"val_index\": idx_val,\n",
    "    \"test_index\": idx_test,\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Unified data object\n",
    "# ----------------------------\n",
    "data = {\n",
    "    \"num_nodes\": num_nodes,\n",
    "    \"edge_index\": edge_index,\n",
    "    \"x\": x,\n",
    "    \"y\": y,\n",
    "    \"sensitive\": sensitive,\n",
    "    \"split\": index_split,\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Save\n",
    "# ----------------------------\n",
    "Path(DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "save_path = Path(DATA_DIR) / OUTPUT_NAME\n",
    "torch.save(data, save_path)\n",
    "\n",
    "print(f\"Saved unified dataset to {save_path}\")\n",
    "print(\"Nodes:\", num_nodes)\n",
    "print(\"Edges:\", edge_index.shape[1])\n",
    "print(\"Train / Val / Test:\", len(idx_train), len(idx_val), len(idx_test))\n"
   ],
   "id": "6fc9305480a2f7f5",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Adding self-loops to the credit dataset since it does not have any",
   "id": "6dbdf945779e10c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-28T20:09:28.332662Z",
     "start_time": "2026-01-28T20:09:28.312932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "data = torch.load(\"../data/credit_no_self_loops.pt\")\n",
    "\n",
    "edge_index = data[\"edge_index\"]\n",
    "num_nodes = data[\"num_nodes\"]\n",
    "\n",
    "self_loops = torch.arange(num_nodes, dtype=torch.long)\n",
    "self_loop_edges = torch.stack([self_loops, self_loops], dim=0)\n",
    "\n",
    "edge_index = torch.cat([edge_index, self_loop_edges], dim=1)\n",
    "\n",
    "data[\"edge_index\"] = edge_index\n",
    "torch.save(data, \"../data/credit.pt\")\n",
    "\n",
    "print(f\"Added {self_loop_edges.size(1)} self-loops.\")\n",
    "print(\"Total edges:\", edge_index.shape[1])"
   ],
   "id": "2b10377e0dd08c2a",
   "execution_count": 3,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
